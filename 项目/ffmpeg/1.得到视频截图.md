## 概要

每种文件格式都是一个**容器（Format）**，而格式决定了内部数据的存放方式，例如常见的AVI格式等。

而在容器内部则有许多的**信息流（Stream）**：例如视频流和音频流。

流内的每条数据通常称为一个**帧（frame）**。每个数据流都使用特定的**编码器（codec）**进行编码，编码器定义了实际是据是如何编码和解码的。

通常会将流中的数据读取到**包（Packet）**内，数据包可包含被解码成原始帧的数据片段，从而供我们使用这些数据。而我们要将一个或多个完整的帧放到一个包里。

整体过程基本如下：

```
10 OPEN video_stream FROM video.avi
20 READ packet FROM video_stream INTO frame
30 IF frame NOT COMPLETE GOTO 20
40 DO SOMETHING WITH frame
50 GOTO 20
```

## 打开文件

首先需要加载一些库文件：

```c
#include <libavcodec/avcodec.h>
#include <libavformat/avformat.h>
#include <ffmpeg/swscale.h>
...
int main(int argc, charg *argv[]) {
av_register_all();   // 注册所有的文件和库
```

`av_register_all()`只需要调用一次。加载完成后打开视频文件：

```c
AVFormatContext *pFormatCtx = NULL;

// 打开视频文件
if (avformat_open_input(&pFormatCtx, argv[1], NULL, NULL) != 0)
    return -1;
```

执行`main`函数时第一个参数argv[1]指定文件名称，这个函数会将读取的内容填充到`AVFormatContext`内，**但也只是填充文件的头部**，所以要获得真正的内容我们需要获得里面的流信息：

```c
// 得到里面的流信息
if (avformat_find_stream_info(pFormatCtx, NULL)<0)
    return -1;
```

此函数将视频的流信息填充到了`pFormatCtx->streams`里了，它是一个指针数组，数组的容量为`pFormatCtx->nb_streams`。接下来就可以在这些Streams里找到视频流（video stream）。

```c
int i;
AVCodecContext *pCodecCtxOrig = NULL;
AVCodecContext *pCodecCtx = NULL;

// 查找出现的video stream
int videoStream=1;
for(i=0; i<pFormatCtx->nb_streams; i++) {
    if(pFormatCtx->streams[i]->codec->codec_type==AVMEDIA_TYPE_VIDEO) {
        videoStream=i;   // 记录video stream的下标
        break;
    }
}

if(videoStream==-1)
    return -1;
pCodecCtx = pFormatCtx->streams[videoStream]->codec;  // 得到这个流的编码器上下文
```

与流信息编码有关的我们称为**编码上下文（codec context）**，它包含了此信息使用的编码器的所有相关信息。我们得到了它的指针后，还需要找到真正的编码/解码器，然后打开它

```c
AVCodec *pCodec = NULL:

// 找到video stream的解码器
pCodec=avcodec_find_decoder(pCodecCtx->codec_id);
if(pCodec==NULL) {
    fprintf(stderr, "Unsupported codec!\n");
    return -1;
}

// 复制编码的上下文
pCodecCtx = avcodec_alloc_context3(pCodec);
if(avcodec_copy_context(pCodecCtx, pCodecCtxOrig) != 0) {
    fprintf(stderr, "Couldn't copy codec context");
}

// 打开编码器
if(avcodec_open2(pCodecCtx, pCodec)<0)
    return -1;
```

注意我们不要直接使用源video stream中的`AVCodecContext`，需要使用函数`avcodec_copy_context()`来将上下文（context）拷贝到一个新的位置。

## 存储数据

得到了和编码器相关的信息（具体编码器、编码器上下文）后，需要存储那些帧：

```c
AVFrame *pFrame = NULL:

// 分配内存
pFrame=av_frame_alloc();
```

我们要将我们的帧转换为RGB格式，ffmpeg会替我们做。我们首先给转换后的帧分配一些frame：

```c
// 先给转换后的帧分配frame
AVFrame *pFrameRGB=av_frame_alloc();
if(pFrameRGB==NULL)
    return -1;
```

即使已经分配了frame，当需要转换原始数据时，仍然需要有一个存放frame的内存。使用方法`avpicture_get_size`来得到目标尺寸，进而手动的分配内存。

```c
uint8_t *buffer = NULL:
int numBytes;
// 得到需要的内存大小并分配
numBytes = avpicture_get_size(PIX_FMT_RGB24, pCodecCtx->width, pCodecCtx->height);
buffer=(uint8_t *)av_malloc(numBytes*sizeof(uint8_t));
```

`av_malloc`是ffmpeg的对于malloc包装的内存分配方法，保证了内存地址是对齐的。但它不会替你解决内存泄露等问题。

然后使用`avpicture_fill`来把Frame和我们新申请的内存关联起来。`AVPicture`是`AVFrame`的子结构：`AVFrame`结构的开始部分和`AVPicture`结构相同。

```c
// 分配固定内存给
avpicture_fill((AVPicture *)pFrameRGB, bufferm PIX_FMT_RGB24, pCodecCtx->width, pCodecCtx->height);
```

接下来就可以读取数据了。

## 读取数据

接下来读取在Packet中的整个video stream数据，解码到我们新申请的frame。完成后我们就进行转换和存储。

```c
struct SwsContext *sws_ctx = NULL;
int frameFinished;
AVPacket packet;

// 初始化 SWS context 供程序使用
sws_ctx = sws_getContext(pCodecCtx->width,
    pCodecCtx->height,
    pCodecCtx->pix_fmt,
    pCodecCtx->width,
    pCodecCtx->height,
    PIX_FMT_RGB24,
    SWS_BILINEAR,
    NULL,
    NULL,
    NULL
    );

while(av_read_frame(pFormatCtx, &packet)>=0) {
  // 查看这个packet是不是来自刚才提取的videoStream
  if(packet.stream_index==videoStream) {
	// 解码这个video stream
    avcodec_decode_video2(pCodecCtx, pFrame, &frameFinished, &packet);
    
    // 如果解码成功
    if(frameFinished) {
    // 进行格式转换，为RGB
        sws_scale(sws_ctx, (uint8_t const * const *)pFrame->data,
		  pFrame->linesize, 0, pCodecCtx->height,
		  pFrameRGB->data, pFrameRGB->linesize);
	
        // 将这个frame存储到硬盘上
        if(++i<=5)
          SaveFrame(pFrameRGB, pCodecCtx->width, 
                    pCodecCtx->height, i);
    }
  }
    
  // 释放packet
  av_free_packet(&packet);
}
```

`av_read_frame()`读取一个packet并放到`AVPacket`结构中，`avcodec_decod_video()`将packet转换为frame。但可能解码后不一定有一帧的全部信息，所以`avcodec_decod_video()`设置了标志位`frameFinished`，当有下一帧的数据时它为True。最后使用`sws_scale()`将原本格式（pCodecCtx->pix_fmt）转换为RGB。

可以将一个`AVFrame`指针变为`AVPicture`指针，最后将帧以及高度、宽度信息传递给自定义的`SaveFrame`函数。`SaveFrame()`函数用来将RGB信息伊PPM格式写到硬盘上。

```c
void SaveFrame(AVFrame *pFrame, int width, int height, int iFrame) {
  FILE *pFile;
  char szFilename[32];
  int  y;
  
  // Open file
  sprintf(szFilename, "frame%d.ppm", iFrame);
  pFile=fopen(szFilename, "wb");
  if(pFile==NULL)
    return;
  
  // Write header, width and height of file
  fprintf(pFile, "P6\n%d %d\n255\n", width, height);
  
  // Write pixel data，one row each time
  for(y=0; y<height; y++)
    fwrite(pFrame->data[0]+y*pFrame->linesize[0], 1, width*3, pFile);
  
  // Close file
  fclose(pFile);
}
```

回归到`main()`函数，写入硬盘完成后，就需要释放一些东西：

```c
// Free the RGB image
av_free(buffer);
av_free(pFrameRGB);

// Free the YUV frame
av_free(pFrame);

// Close the codecs
avcodec_close(pCodecCtx);
avcodec_close(pCodecCtxOrig);

// Close the video file
avformat_close_input(&pFormatCtx);

return 0;
```

使用`av_free`函数来释放分配的内存，包括用`avcode_alloc_frame`和`av_malloc`来申请的。



```
./configure --prefix=/usr/local/ffmpeg  --enable-gpl --enable-nonfree --enable-libfdk-aac --enable-libx264 --enable-libx265 --enable-filter=delogo --enable-debug --disable-optimizations --enable-libspeex --enable-shared --enable-pthreads
```

