## 用户态和内核态区别

### 1.操作系统需要两种CPU状态：

- 内核态（Kernel Mode）：运行操作系统程序

- 用户态（User Mode）：运行用户程序

### 2.指令划分：

- 特权指令：只能由操作系统使用、用户程序不能使用的指令。 举例：启动I/O  内存清零 修改程序状态字 设置时钟  允许/禁止终端  停机

- 非特权指令：用户程序可以使用的指令。 举例：控制转移 算数运算 取数指令  访管指令（使用户程序从用户态陷入内核态）

###  3.特权级别：

**特权环：R0、R1、R2和R3**。R0相当于内核态，R3相当于用户态；不同级别能够运行不同的指令集合；

### 4.CPU状态之间的转换：

- **用户态--->内核态：**唯一途径是通过中断、异常、陷入机制（访管指令）

- **内核态--->用户态：**设置程序状态字PSW

### 5.内核态与用户态的区别：

1. **内核态与用户态是操作系统的两种运行级别，当程序运行在3级特权级上时，就可以称之为运行在用户态。**因为这是最低特权级，是普通的用户进程运行的特权级，大部分用户直接面对的程序都是运行在用户态；
2. **当程序运行在0级特权级上时，就可以称之为运行在内核态。**
3. **运行在用户态下的程序****不能直接访问操作系统内核数据结构和程序****。当我们在系统中执行一个程序时，大部分时间是运行在用户态下的，在其需要操作系统帮助完成某些它没有权力和能力完成的工作时就会切换到内核态。**
4. **这两种状态的主要差别是**：

处于用户态执行时，进程所能访问的内存空间和对象受到限制，其所处于占有的处理机是可被抢占的 ；

而处于核心态执行中的进程，则能访问所有的内存空间和对象，且所占有的处理机是不允许被抢占的。

### 6. 通常来说，以下三种情况会导致用户态到内核态的切换：

1. 系统调用：**这是用户态进程主动要求切换到内核态的一种方式**，**用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作。**而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的int 80h中断。

2. 异常：当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。

3. 外围设备的中断：**当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号**，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。

**这3种方式是系统在运行时由用户态转到内核态的最主要方式，其中系统调用可以认为是用户进程主动发起的，异常和外围设备中断则是被动的。**

## 信号与信号量区别

**信号是事件发生时对进程的通知机制，有时也称为软件中断**。信号与硬件中断的相似之处在于打断了程序执行的正常流程，大多数情况下，无法预测信号到达的准确时间。一个（具有合适权限的）进程能够向另一进程发送信号。这一做法可作为一种同步技术，甚至是进程间通信（IPC）的原始形式。进程也可以向自身发送信号。但是发往进程的诸多信号，通常都是源于内核。

有时需要确保一段代码不被传递来的信号中断，为了做到这点，可将信号添加到进程的信号掩码中——目前会阻塞该组信号的到达。如果所产生的信号属于阻塞之列，那么信号将保持等待状态，直至稍后对其解除阻塞（从掩码信号中移除）。进程可使用各种系统调用对其信号掩码添加和移除信号。

以下时间可引发内核为进程产生信号：

1. 硬件异常。硬件检测到一个错误条件并通知内核，随机再由内核发送相应信号给相关进程。硬件异常的例子包括执行一条异常的机器语言指令。例如：被0除， 或者引用了无法访问的内存区域。

2. 用户键入了能够产生信号的终端特殊字符。其中包括中断字符（Ctrl+C）、暂停字符（Ctrl+Z）。

3. 发生了软件事件。例如，针对文件描述符的输出变为有效，调整了终端窗口大小，定时器到期，进程执行的CPU时间超限，或者该进程的某个子进程退出。

针对每个信号都定义了一个唯一的（小）整数，从一开始顺序展开。为了可移植性，一般都用在<signal.h>中定义的符号名（形如SIGxxxx）而不是用数字。例如，当用户键入中断字符时，将传递给进程SIGINT信号（信号编号为2）。

信号有两大类：

（1）用于内核向进程通知事件，构成所谓传统或标准信号。标准信号范围：1～31。

（2）由实时信号构成。

信号因某些事件而产生后，会于稍后被传递给某一进程，进程也会采取某些措施来相应信号。在产生和到达期间，信号处于等待状态（pending）。

信号到达后，进程视具体信号执行如下默认操作之一。

（1）忽略信号：内核将信号丢弃，信号对进程没有任何影响（进程永远不知道曾经出现过该信号）。

（2）终止（杀死）进程：这有时是指进程异常终止，而不是进程因调用exit()而发生的正常终止。

（3）产生核心转储文件，同时进程终止：核心转储文件包含对进程虚拟内存的镜像，可将其加载到调试器中以检查进程终止时的状态。

（4）停止（不是终止）进程：使进程暂停执行。

（5）执行之前被暂停的进程。

除了根据特定信号而采取默认行为之外，程序也能改变信号到达时的响应行为。也将次称之为对信号的处置（disposition）设置。程序可以将对信号的处置设置为如下之一。

（1）采取默认行为。

（2）忽略信号。

（3）执行信号处理器程序。

信号处理其是由程序员编写的函数，用于为响应传递来的信号而执行适当任务。例如shell为SIGINT信号提供了一个处理器程序，令其停止当前正在执行的工作，并返回到（shell的）主输入循环，并再次向用户呈现shell提示符。

除了默认处置外，无法将信号处置设置为终止进程或者转储核心。

<hr>

操作系统中的信号量在解决线程之间的同步中起着非常大的作用，那么什么是信号量呢？

百度百科：信号量(Semaphore)，有时被称为信号灯，是在多线程环境下使用的一种设施，是可以用来保证两个或多个关键代码段不被并发调用。在进入一个关键代码段之前，线程必须获取一个信号量；一旦该关键代码段完成了，那么该线程必须释放信号量。其它想进入该关键代码段的线程必须等待直到第一个线程释放信号量。

维基百科：信号量（英语：Semaphore）又称为信号量、旗语，是一个同步对象，用于保持在0至指定最大值之间的一个计数值。当线程完成一次对该semaphore对象的等待（wait）时，该计数值减一；当线程完成一次对semaphore对象的释放（release）时，计数值加一。当计数值为0，则线程等待该semaphore对象不再能成功直至该semaphore对象变成signaled状态。semaphore对象的计数值大于0，为signaled状态；计数值等于0，为nonsignaled状态.

其中，信号量又分为两种：二进制信号量和计数信号量。

信号量的概念是由荷兰计算机科学家艾兹赫尔·戴克斯特拉（Edsger W. Dijkstra）发明的，广泛的应用于不同的操作系统中。在系统中，给予每一个进程一个信号量，代表每个进程目前的状态，未得到控制权的进程会在特定地方被强迫停下来，等待可以继续进行的信号到来。如果信号量是一个任意的整数，通常被称为计数信号量（Counting semaphore），或一般信号量（general semaphore）；如果信号量只有二进制的0或1，称为二进制信号量（binary semaphore）。在linux系统中，二进制信号量（binary semaphore）又称互斥锁（Mutex）。

其中，信号量又存在着两种操作，分别为V操作与P操作，V操作会增加信号量 S的数值，P操作会减少它。

具体的运作方式如下：

初始化，给与它一个非负数的整数值。

运行 P（wait()），信号量S的值将被减少。企图进入临界区块的进程，需要先运行 P（wait()）。当信号量S减为负值时，进程会被挡住，不能继续；当信号量S不为负值时，进程可以获准进入临界区块。

运行 V（又称signal()），信号量S的值会被增加。结束离开临界区块的进程，将会运行 V（又称signal()）。当信号量S不为负值时，先前被挡住的其他进程，将可获准进入临界区块。

以上是维基百科对于信号量的具体解释，下面是我自己对于信号量的一个理解。

  信号量实际上就是一个值，这个值被用来解决临界区问题以及实现进程在多处理器环境下的进程同步。

  其中，两个最重要的信号量为二进制信号量和计数信号量，计数信号量可以表示为非负的整数而二进制信号量只存在0和1两个值。

## 同一进程中共享哪些资源

在很多现代操作系统中，一个进程的（虚）地址空间大小为4G，分为**系统空间**和**用户空间**两部分，==系统空间为所有进程共享，而用户空间是独立的==。一个进程中的所有线程共享该进程的地址空间，但它们有各自独立的**栈(stack)**。堆(heap)的分配与栈有所不同，一般是一个进程有一个C运行时堆，==这个堆为本进程中所有线程共享==。 线程切换的时候实际上切换的是一个可以称之为线程控制块的结构，里面保存所有将来用于恢复线程环境必须的信息，包括所有必须保存的寄存器集，线程的状态等。

- **堆：**　是大家共有的空间，分全局堆和局部堆。全局堆就是所有没有分配的空间，局部堆就是用户分配的空间。堆在操作系统对进程初始化的时候分配，运行过程中也可以向系统要额外的堆，但是记得用完了要还给操作系统，要不然就是内存泄漏。

- **栈：**是个线程独有的，保存其运行状态和局部自动变量的。栈在线程开始的时候初始化，==每个线程的栈互相独立==，因此，栈是thread safe的。操作系统在切换线程的时候会自动的切换栈，就是切换SS／ESP寄存器。栈空间不需要在高级语言里面显式的分配和释放。

**进程简说：**

进程是为了在CPU上实现多道编程而发明的一个概念。

事实上我们说线程是进程里面的一个执行上下文，或者执行序列，显然一个进程可以同时拥有多个执行序列，更加详细的描述是，舞台上有多个演员同时出场，而这些演员和舞台就构成了一出戏，类比进程和线程，每个演员是一个线程，舞台是地址空间，这个同一个地址空间里面的所有线程就构成了进程。

比如当我们打开一个word程序，其实已经同时开启了多个线程，这些线程一个负责显示，一个接受输入，一个定时进行存盘，这些线程一起运转让我们感到我们的输入和屏幕显示同时发生，而不用键入一些字符等好长时间才能显示到屏幕上。

**线程管理：**

将线程共有的信息存放在进程控制块中，将线程独有的信息存放在线程控制块中。

那么如何区分哪些信息是共享的？哪些信息是独享的呢？

一般的评价标准是：如果某些资源不独享会导致线程运行错误，则该资源就由每个线程独享，而其他资源都由进程里面的所有线程共享。

|    线程共享资源    | 线程独享资源 |
| :----------------: | ------------ |
|      地址空间      | 程序计数器   |
|      全局变量      | 寄存器       |
|     打开的文件     | 栈           |
|       子进程       | 状态字       |
|        闹铃        |              |
| 信号及信号服务程序 |              |
|      记账信息      |              |

一般情况下进程共享资源与独享资源的划分

那么对于进程及线程的实现做如何解释呢？

首先应该明白进程的调度，创建等实质上都是由操作系统实现的，所以说进程的实现只能由操作系统内核来实现，而不存在用户态实现的情况。但是对于线程就不同了，线程的管理者可以是用户也可以是操作系统本身，线程是进程内部的东西，当然存在由进程直接管理线程的可能性。因此线程的实现就应该分为内核态线程实现和用户态线程实现。

================================================================================================================

内核态线程实现：

线程是进程的不同执行序列，也就是说线程是独立运行的基本单位，也是CPU调度的基本单位。

那么操作系统是如何实现管理线程的呢？

首先操作系统向管理进程一样，应该保持维护线程的所有资源，将线程控制块存放在操作系统的内核空间中。那么此时操作系统就同时掌管进程控制块和线程控制块。

操作系统管理线程的好处是：

1.用户编程简单；

2.如果一个线程执行阻塞操作，操作系统可以从容的调度另外一个线程的执行。

内核线程的实现缺点是：

1.效率低，因为线程在内核态实现，每次线程切换都需要陷入到内核，由操作系统来调度，而有用户态切换到内核态是要话费很多时间的，另外内核态实现会占用内核稀有的资源，因为操作系统要维护线程列表，操作系统所占内核空间一旦装载后就无法动态改变，并且线程的数量远远大于进程的数量，随着线程数的增加内核将耗尽；

2.内核态的实现需要修改操作系统，这个是谁都不想要做的事情；

====================================================================================================================

那么用户态是如何实现管理线程的呢？

用户态管理线程就是用户自己做线程的切换，自己管理线程的信息，操作系统无需知道线程的存在。

在用户态下进行线程的管理需要用户创建一个调度线程。一个线程在执行完一段时间后主动把资源释放给其他线程使用，而在内核台下则无需如此，因为操作系统可通过周期性的时钟中断把控制权夺过来，在用户态实现情况下，执行系统的调度器也是线程，没有能力夺取控制权。

用户态实现有什么优点？

首先是灵活，因为操作系统不用知道线程的存在，所以任何操作系统上都能应用；

其次，线程切换快，因为切换在用户态进行，无需陷入带内核态；

再次，不用修改操作系统实现容易。

用户态实现的缺点呢？

首先编程起来很诡异，由于在用户台下各个进程间需要相互合作才能正常运转。那么在编程时必须考虑什么情况下让出CPU，让其他的线程运行，而让出时机的选择对线程的效率和可靠性有很大影响，这个并不容易做到；

其次，用户态线程实现无法完全达到线程提出所要达到的目的：进程级多道编程；，如果在执行过程中一个线程受阻，它将无法将控制权交出来，这样整个进程都无法推进。操作系统随即把CPU控制权交给另外一个进程。这样，一个线程受阻造成整个进程受阻，我们期望的通过线程对进程实施分身的计划就失败了。这是用户态线程致命的缺点。

调度器激活：线程阻塞后，CPU控制权交给了操作系统，要激活受阻进程的线程，唯一的办法就是让操作系统在进程切换时先不切换，而是通知受阻的进程执行系统（即调用执行系统），并问其是否还有别的线程可以执行。如果有，将CPU控制权交给该受阻进程的执行系统线程，从而调度另一个可以执行的线程到CPU上。一个进程挂起后，操作系统并不立即切换到别的进程上，而是给该进程二次机会，让其继续执行。如果该进程只有一个线程，或者其所有线程都已经阻塞，则控制权将再次返回给操作系统。而现在，操作系统就会切换到其他线程了。

=============================================================================================================================

**现在操作系统的线程实现模型：**

鉴于用户态与内核态都存在缺陷，现代操作将两者结合起来。用户态的执行负责进程内部线程在非阻塞时的切换；内核态的操作系统负责阻塞线程的切换，即我们同时实现内核态和用户态线程管理。每个内核态线程可以服务一个或者更多个用户态线程。

## Linux中的零拷贝

### 引文

在写一个服务端程序时（Web Server或者文件服务器），文件下载是一个基本功能。这时候服务端的任务是：将服务端主机磁盘中的文件不做修改地从已连接的socket发出去，我们通常用下面的代码完成：

```c
while((n = read(diskfd, buf, BUF_SIZE)) > 0) {
		write(sockfd, buf , n);
}
```

基本操作就是循环的从磁盘读入文件内容到缓冲区，再将缓冲区的内容发送到socket。但是由于Linux的I/O操作默认是缓冲I/O。这里面主要使用的也就是read和write两个系统调用，我们并不知道操作系统在其中做了什么。实际上在以上I/O操作中，发生了多次的数据拷贝。

- 当应用程序访问某块数据时，操作系统首先会检查，是不是最近访问过此文件，文件内容是否缓存在**内核缓冲区**，如果是，操作系统则直接根据read系统调用提供的buf地址，将内核缓冲区的内容拷贝到buf所指定的用户空间缓冲区中去。
- 如果不是，操作系统则首先将磁盘上的数据拷贝的内核缓冲区，这一步目前主要依靠DMA来传输，然后再把内核缓冲区上的内容拷贝到**用户缓冲区**中。
- 接下来，write系统调用再把用户缓冲区的内容拷贝到网络堆栈相关的内核缓冲区中，最后socket再把内核缓冲区的内容发送到网卡上。

说了这么多，不如看图清楚：

![img](https:////note.youdao.com/src/37BDE68744344C2BB60DF1A53FF1B9B9)

数据拷贝

从上图中可以看出，共产生了四次数据拷贝，即使使用了DMA来处理了与硬件的通讯，CPU仍然需要处理两次数据拷贝，与此同时，在用户态与内核态也发生了多次上下文切换，无疑也加重了CPU负担。在此过程中，我们没有对文件内容做任何修改，那么在内核空间和用户空间来回拷贝数据无疑就是一种浪费，而零拷贝主要就是为了解决这种低效性。

### 什么是零拷贝技术（zero-copy）？

零拷贝主要的任务就是避免CPU将数据从一块存储拷贝到另外一块存储，主要就是利用各种零拷贝技术，避免让CPU做大量的数据拷贝任务，减少不必要的拷贝，或者让别的组件来做这一类简单的数据传输任务，让CPU解脱出来专注于别的任务。这样就可以让系统资源的利用更加有效。

我们继续回到引文中的例子，我们如何减少数据拷贝的次数呢？一个很明显的着力点就是==减少数据在内核空间和用户空间来回拷贝==，这也引入了零拷贝的一个类型：==让数据传输不需要经过user space==。

#### 使用mmap

我们减少拷贝次数的一种方法是调用mmap()来代替read调用：

```c
buf = mmap(diskfd,len);
write(sockfd, buf,len);
```

应用程序调用mmap()，磁盘上的数据会通过DMA被拷贝的内核缓冲区，接着操作系统会==把这段内核缓冲区与应用程序共享，这样就不需要把内核缓冲区的内容往用户空间拷贝==。应用程序再调用write(),操作系统直接将内核缓冲区的内容拷贝到socket缓冲区中，==这一切都发生在内核态==，最后，socket缓冲区再把数据发到网卡去。

同样的，看图很简单：

![img](https://note.youdao.com/src/99A0DF0186DE4F5D828CF661E43ACBB3.png)

mmap

使用mmap替代read很明显减少了一次拷贝，当拷贝数据量很大时，无疑提升了效率。但是使用mmap是有代价的。当你使用mmap时，你可能会遇到一些隐藏的陷阱。例如，当你的程序map了一个文件，但是当这个文件被另一个进程截断(truncate)时, write系统调用会因为访问非法地址而被SIGBUS信号终止。SIGBUS信号默认会杀死你的进程并产生一个coredump,如果你的服务器这样被中止了，那会产生一笔损失。

通常我们使用以下解决方案避免这种问题：

1. 为SIGBUS信号建立信号处理程序

当遇到SIGBUS信号时，信号处理程序简单地返回，write系统调用在被中断之前会返回已经写入的字节数，并且errno会被设置成success,但是这是一种糟糕的处理办法，因为你并没有解决问题的实质核心。

1. 使用文件租借锁

通常我们使用这种方法，在文件描述符上使用租借锁，我们为文件向内核申请一个租借锁，当其它进程想要截断这个文件时，内核会向我们发送一个实时的RT_SIGNAL_LEASE信号，告诉我们内核正在破坏你加持在文件上的读写锁。这样在程序访问非法内存并且被SIGBUS杀死之前，你的write系统调用会被中断。write会返回已经写入的字节数，并且置errno为success。

我们应该在mmap文件之前加锁，并且在操作完文件后解锁：

if(fcntl(diskfd, F_SETSIG, RT_SIGNAL_LEASE)==-1){perror("kernel lease set signal");return-1;}/* l_type can be F_RDLCK F_WRLCK  加锁*//* l_type can be  F_UNLCK 解锁*/if(fcntl(diskfd, F_SETLEASE, l_type)){perror("kernel lease set type");return-1;}

使用sendfile#####

从2.1版内核开始，Linux引入了sendfile来简化操作:

\#includessize_t sendfile(int out_fd,int in_fd, off_t *offset, size_t count);

系统调用sendfile()在代表输入文件的描述符in_fd和代表输出文件的描述符out_fd之间传送文件内容（字节）。描述符out_fd必须指向一个套接字，而in_fd指向的文件必须是可以mmap的。这些局限限制了sendfile的使用，使sendfile只能将数据从文件传递到套接字上，反之则不行。

使用sendfile不仅减少了数据拷贝的次数，还减少了上下文切换，数据传送始终只发生在kernel space。

![img](https:////note.youdao.com/src/07CC0082D51F40D289817C9420A1605E)

sendfile系统调用过程

在我们调用sendfile时，如果有其它进程截断了文件会发生什么呢？假设我们没有设置任何信号处理程序，sendfile调用仅仅返回它在被中断之前已经传输的字节数，errno会被置为success。如果我们在调用sendfile之前给文件加了锁，sendfile的行为仍然和之前相同，我们还会收到RT_SIGNAL_LEASE的信号。

目前为止，我们已经减少了数据拷贝的次数了，但是仍然存在一次拷贝，就是页缓存到socket缓存的拷贝。那么能不能把这个拷贝也省略呢？

借助于硬件上的帮助，我们是可以办到的。之前我们是把页缓存的数据拷贝到socket缓存中，实际上，我们仅仅需要把缓冲区描述符传到socket缓冲区，再把数据长度传过去，这样DMA控制器直接将页缓存中的数据打包发送到网络中就可以了。

总结一下，sendfile系统调用利用DMA引擎将文件内容拷贝到内核缓冲区去，然后将带有文件位置和长度信息的缓冲区描述符添加socket缓冲区去，这一步不会将内核中的数据拷贝到socket缓冲区中，DMA引擎会将内核缓冲区的数据拷贝到协议引擎中去，避免了最后一次拷贝。

![img](https:////note.youdao.com/src/596578F6C0A440E8A6CECB3D1EAD7E08)

带DMA的sendfile

不过这一种收集拷贝功能是需要硬件以及驱动程序支持的。

使用splice#####

sendfile只适用于将数据从文件拷贝到套接字上，限定了它的使用范围。Linux在2.6.17版本引入splice系统调用，用于在两个文件描述符中移动数据：

\#define _GNU_SOURCE         /* See feature_test_macros(7) */#includessize_t splice(int fd_in, loff_t *off_in,int fd_out, loff_t *off_out, size_t len,unsignedint flags);

splice调用在两个文件描述符之间移动数据，而不需要数据在内核空间和用户空间来回拷贝。他从fd_in拷贝len长度的数据到fd_out，但是有一方必须是管道设备，这也是目前splice的一些局限性。flags参数有以下几种取值：

- SPLICE_F_MOVE ：尝试去移动数据而不是拷贝数据。这仅仅是对内核的一个小提示：如果内核不能从pipe移动数据或者pipe的缓存不是一个整页面，仍然需要拷贝数据。Linux最初的实现有些问题，所以从2.6.21开始这个选项不起作用，后面的Linux版本应该会实现。
- ** SPLICE_F_NONBLOCK** ：splice 操作不会被阻塞。然而，如果文件描述符没有被设置为不可被阻塞方式的 I/O ，那么调用 splice 有可能仍然被阻塞。
- ** SPLICE_F_MORE**： 后面的splice调用会有更多的数据。

splice调用利用了Linux提出的管道缓冲区机制， 所以至少一个描述符要为管道。

以上几种零拷贝技术都是减少数据在用户空间和内核空间拷贝技术实现的，但是有些时候，数据必须在用户空间和内核空间之间拷贝。这时候，我们只能针对数据在用户空间和内核空间拷贝的时机上下功夫了。Linux通常利用写时复制(copy on write)来减少系统开销，这个技术又时常称作COW。

由于篇幅原因，本文不详细介绍写时复制。大概描述下就是：如果多个程序同时访问同一块数据，那么每个程序都拥有指向这块数据的指针，在每个程序看来，自己都是独立拥有这块数据的，只有当程序需要对数据内容进行修改时，才会把数据内容拷贝到程序自己的应用空间里去，这时候，数据才成为该程序的私有数据。如果程序不需要对数据进行修改，那么永远都不需要拷贝数据到自己的应用空间里。这样就减少了数据的拷贝。写时复制的内容可以再写一篇文章了。。。

除此之外，还有一些零拷贝技术，比如传统的Linux I/O中加上O_DIRECT标记可以直接I/O，避免了自动缓存，还有尚未成熟的fbufs技术，本文尚未覆盖所有零拷贝技术，只是介绍常见的一些，如有兴趣，可以自行研究，一般成熟的服务端项目也会自己改造内核中有关I/O的部分，提高自己的数据传输速率。