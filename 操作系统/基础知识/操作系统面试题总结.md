### 1. 进程同步

进程同步的主要任务：是对多个相关进程在执行次序上进行协调，以使并发执行的诸进程之间能有效地共享资源和相互合作，从而使程序的执行具有可再现性。同步机制遵循的原则：

　　（1）空闲让进；

　　（2）忙则等待（保证对临界区的互斥访问）；

　　（3）有限等待（有限代表有限的时间，避免死等）；

　　（4）让权等待（当进程不能进入自己的临界区时，应该释放处理机，以免陷入忙等状态）。

### 2.进程与线程的区别和联系？

- **进程**是具有一定独立功能的程序关于某个数据集合上的一次运行活动，进程是系统进行资源分配和调度的一个独立单位。
- **线程**是进程的一个实体，是CPU调度和分派的基本单位，它是比进程更小的能独立运行的基本单位。

#### 进程和线程的关系

（1）**一个线程只能属于一个进程，而一个进程可以有多个线程**，但至少有一个线程。线程是操作系统可识别的最小执行和调度单位。

（2）**资源分配给进程，同一进程的所有线程共享该进程的所有资源。** 同一进程中的多个线程共享代码段(代码和常量)，数据段(全局变量和静态变量)，扩展段(堆存储)。但是每个线程拥有自己的栈段，栈段又叫运行时段，用来存放所有局部变量和临时变量。

（3）**处理机分给线程，**即真正在处理机上运行的是线程。

（4）线程在执行过程中，需要协作同步。不同进程的线程间要利用消息通信的办法实现同步。

#### 进程与线程的区别？

（1）进程有自己的独立地址空间，线程没有

（2）进程是资源分配的最小单位，线程是CPU调度的最小单位

（3）进程和线程通信方式不同(线程之间的通信比较方便。同一进程下的线程共享数据（比如全局变量，静态变量），通过这些数据来通信不仅快捷而且方便，当然如何处理好这些访问的同步与互斥正是编写多线程程序的难点。而进程之间的通信只能通过[进程通信](http://baike.baidu.com/view/549640.htm)的方式进行。)

（4）进程上下文切换开销大，线程开销小

（5）一个进程挂掉了不会影响其他进程，而线程挂掉了会影响其他线程

（6）对进程进程操作一般开销都比较大，对线程开销就小了 

####  为什么进程上下文切换比线程上下文切换代价高？

进程切换分两步：

1. 切换页目录以使用新的地址空间

2. 切换内核栈和硬件上下文

对于linux来说，线程和进程的最大区别就在于地址空间，对于线程切换，第1步是不需要做的，第2是进程和线程切换都要做的。

切换的性能消耗：

1. 线程上下文切换和进程上下问切换一个最主要的区别是**线程的切换虚拟内存空间依然是相同的，但是进程切换是不同的**。这两种上下文切换的处理都是通过操作系统内核来完成的。内核的这种切换过程伴随的最显著的性能损耗是将寄存器中的内容切换出。

2. 另外一个隐藏的损耗是上下文的切换会扰乱处理器的**缓存机制**。简单的说，一旦去切换上下文，处理器中所有已经缓存的内存地址一瞬间都作废了。还有一个显著的区别是当你改变虚拟内存空间的时候，处理的页表缓冲或者相当的东西会被全部刷新，这将导致内存的访问在一段时间内相当的低效。但是在线程的切换中，不会出现这个问题。

首先来一句概括的总论：**进程和线程都是一个时间段的描述，是CPU工作时间段的描述。**

**下面细说背景**：

CPU+RAM+各种资源（比如显卡，光驱，键盘，GPS, 等等外设）构成我们的电脑，但是电脑的运行，实际就是CPU和相关寄存器以及RAM之间的事情。

**一个最最基础的事实**：CPU太快，太快，太快了，寄存器仅仅能够追的上他的脚步，RAM和别的挂在各总线上的设备完全是望其项背。那当多个任务要执行的时候怎么办呢？轮流着来?或者谁优先级高谁来？不管怎么样的策略，一句话就是在CPU看来就是轮流着来。

**一个必须知道的事实**：执行一段程序代码，实现一个功能的过程介绍 ，当得到CPU的时候，相关的资源必须也已经就位，就是显卡啊，GPS啊什么的必须就位，然后CPU开始执行。这里除了CPU以外所有的就构成了这个程序的执行环境，也就是我们所定义的程序上下文。当这个程序执行完了，或者分配给他的CPU执行时间用完了，那它就要被切换出去，等待下一次CPU的临幸。在被切换出去的最后一步工作就是保存程序上下文，因为这个是下次他被CPU临幸的运行环境，必须保存。

**串联起来的事实**：前面讲过在CPU看来所有的任务都是一个一个的轮流执行的，具体的轮流方法就是：**先加载程序A的上下文，然后开始执行A，保存程序A的上下文，调入下一个要执行的程序B的程序上下文，然后开始执行B,保存程序B的上下文**。

**========= 重要的东西出现了========**

进程和线程*就是这样的背景出来的***，两个名词不过是对应的CPU时间段的描述，名词就是这样的功能。**

- **进程就是包换上下文切换的程序执行时间总和** = **CPU加载上下文+CPU执行+CPU保存上下文**

**线程是什么呢？**

进程的颗粒度太大，每次都要有上下的调入，保存，调出。如果我们把进程比喻为一个运行在电脑上的软件，那么一个软件的执行不可能是一条逻辑执行的，必定有多个分支和多个程序段，就好比要实现程序A，实际分成 a，b，c等多个块组合而成。那么这里具体的执行就可能变成：

程序A得到CPU =>CPU加载上下文，开始执行程序A的a小段，然后执行A的b小段，然后再执行A的c小段，最后CPU保存A的上下文。

这里a，b，c的执行是共享了A的上下文，CPU在执行的时候没有进行上下文切换的。这**里的a，b，c就是线程，也就是说线程是共享了进程的上下文环境、更为细小的CPU时间段。**

**到此全文结束，再一个总结：**

**进程和线程都是一个时间段的描述，是CPU工作时间段的描述，不过是颗粒大小不同。**

- 进程(process)与线程(thread)最大的区别是**进程拥有自己的地址空间，某进程内的线程对于其他进程不可见，即进程A不能通过传地址的方式直接读写进程B的存储区域**。进程之间的通信需要通过进程间通信(Inter-process communication，IPC)。与之相对的，**同一进程的各线程间之间可以直接通过传递地址或全局变量的方式传递信息**。
- **进程作为操作系统中拥有资源和独立调度的基本单位，可以拥有多个线程。**通常操作系统中运行的一个程序就对应一个进程。在同一进程中，线程的切换不会引起进程切换。在不同进程中进行线程切换，如从一个进程内的线程切换到另一个进程中的线程时，会引起进程切换。**相比进程切换，线程切换的开销要小很多。线程于进程相互结合能够提高系统的运行效率。**

**线程可以分为两类：**

- **用户级线程(user level thread)**：对于这类线程，有关线程管理的所有工作都由应用程序完成，内核意识不到线程的存在。在应用程序启动后，操作系统分配给该程序一个进程号，以及其对应的内存空间等资源。应用程序通常先在一个线程中运行，该线程被成为主线程。在其运行的某个时刻，可以通过调用线程库中的函数创建一个在相同进程中运行的新线程。**用户级线程的好处是非常高效，不需要进入内核空间，但并发效率不高。**
- **内核级线程(kernel level thread)**：对于这类线程，有关线程管理的所有工作由内核完成，应用程序没有进行线程管理的代码，只能调用内核线程的接口。内核维护进程及其内部的每个线程，调度也由内核基于线程架构完成。内核级线程的好处是，**内核可以将不同线程更好地分配到不同的CPU，以实现真正的并行计算。**

事实上，在现代操作系统中，**往往使用组合方式实现多线程，即线程创建完全在用户空间中完成，并且一个应用程序中的多个用户级线程被映射到一些内核级线程上，相当于是一种折中方案。**

### 6.进程调度

**调度算法：（很重要）**

**FIFO或First Come, First Served (FCFS)先来先服务**

- 调度的顺序就是任务到达就绪队列的顺序。
- 公平、简单(FIFO队列)、非抢占、不适合交互式。
- 未考虑任务特性，平均等待时间可以缩短。

**Shortest Job First (SJF)**

- 最短的作业(CPU区间长度最小)最先调度。
- SJF可以保证最小的平均等待时间。

**Shortest Remaining Job First (SRJF)**

- SJF的可抢占版本，比SJF更有优势。
- SJF(SRJF): 如何知道下一CPU区间大小？根据历史进行预测: 指数平均法。

**优先权调度**

- 每个任务关联一个优先权，调度优先权最高的任务。
- 注意：优先权太低的任务一直就绪，得不到运行，出现“饥饿”现象。

**Round-Robin(RR)轮转调度算法**

- 设置一个时间片，按时间片来轮转调度（“轮叫”算法）
- 优点: 定时有响应，等待时间较短；缺点: 上下文切换次数较多；
- 时间片太大，响应时间太长；吞吐量变小，周转时间变长；当时间片过长时，退化为FCFS。

**多级队列调度**

- 按照一定的规则建立多个进程队列
- 不同的队列有固定的优先级（高优先级有抢占权）
- 不同的队列可以给不同的时间片和采用不同的调度方法
- 存在问题1：没法区分I/O bound和CPU bound；
- 存在问题2：也存在一定程度的“饥饿”现象；

**多级反馈队列**

- **在多级队列的基础上，任务可以在队列之间移动，更细致的区分任务。**
- **可以根据“享用”CPU时间多少来移动队列，阻止“饥饿”。**
- **最通用的调度算法，多数OS都使用该方法或其变形，如UNIX、Windows等。**

**多级反馈队列调度算法描述:****（很重要）**

![img](https://note.youdao.com/yws/public/resource/1cdba699ec7b6efece55aae67366a809/xmlnote/wcp1578840227309631/B38C1649DF214226B864A8425505BA46/13313)

- 进程在进入待调度的队列等待时，**首先进入优先级最高的Q1等待。**
- **首先调度优先级高的队列中的进程。若高优先级中队列中已没有调度的进程，则调度次优先级队列中的进程。**例如：Q1,Q2,Q3三个队列，只有在Q1中没有进程等待时才去调度Q2，同理，只有Q1,Q2都为空时才会去调度Q3。
- **对于同一个队列中的各个进程，按照时间片轮转法调度。**比如Q1队列的时间片为N，那么Q1中的作业在经历了N个时间片后若还没有完成，则进入Q2队列等待，若Q2的时间片用完后作业还不能完成，一直进入下一级队列，直至完成。
- **在低优先级的队列中的进程在运行时，又有新到达的作业，那么在运行完这个时间片后，CPU马上分配给新到达的作业（****抢占式****）。**

**一个简单的例子**

假设系统中有3个反馈队列Q1,Q2,Q3，时间片分别为2，4，8。现在有3个作业J1,J2,J3分别在时间 0 ，1，3时刻到达。而它们所需要的CPU时间分别是3，2，1个时间片。

- - **时刻0** J1到达。 于是进入到队列1 ，运行1个时间片 ，时间片还未到，此时J2到达。
  - **时刻1** J2到达。 由于时间片仍然由J1掌控，于是等待。J1在运行了1个时间片后，已经完成了在Q1中的2个时间片的限制，于是J1置于Q2等待被调度。现在处理机分配给J2。
  - **时刻2** J1进入Q2等待调度，J2获得CPU开始运行。
  - **时刻3** J3到达，由于J2的时间片未到，故J3在Q1等待调度，J1也在Q2等待调度。
  - **时刻4** J2处理完成，由于J3，J1都在等待调度，但是J3所在的队列比J1所在的队列的优先级要高，于是J3被调度，J1继续在Q2等待。
  - **时刻5** J3经过1个时间片，完成。
  - **时刻6** 由于Q1已经空闲，于是开始调度Q2中的作业，则J1得到处理器开始运行。 J1再经过一个时间片，完成了任务。于是整个调度过程结束。

**9.一个程序从开始运行到结束的完整过程（四个过程）**

1. 预处理：条件编译，头文件包含，宏替换的处理，生成.i文件。
2. 编译：将预处理后的文件转换成汇编语言，生成.s文件
3. 汇编：汇编变为目标代码(机器代码)生成.o的文件
4. 链接：连接目标代码,生成可执行程序

**10.内存池、进程池、线程池。**

首先介绍一个概念“池化技术 ”。池化技术就是：提前保存大量的资源，以备不时之需以及重复使用。池化技术应用广泛，如内存池，线程池，连接池等等。由于在实际应用当中，分配内存、创建进程、线程都会设计到一些系统调用，系统调用需要导致程序从用户态切换到内核态，是非常耗时的操作。因此，当程序中需要频繁的进行内存申请释放，进程、线程创建销毁等操作时，通常会使用内存池、进程池、线程池技术来提升程序的性能。

**线程池**：线程池的原理很简单，类似于操作系统中的缓冲区的概念，它的流程如下：先启动若干数量的线程，并让这些线程都处于睡眠状态，当需要一个开辟一个线程去做具体的工作时，就会唤醒线程池中的某一个睡眠线程，让它去做具体工作，当工作完成后，线程又处于睡眠状态，而不是将线程销毁。

**进程池**与线程池同理。

**内存池**：内存池是指程序预先从操作系统申请一块足够大内存，此后，当程序中需要申请内存的时候，不是直接向操作系统申请，而是直接从内存池中获取；同理，当程序释放内存的时候，并不真正将内存返回给操作系统，而是返回内存池。当程序退出(或者特定时间)时，内存池才将之前申请的内存真正释放。

### 11.动态链接库与静态链接库的区别

**静态库**

- 静态库是一个外部函数与变量的集合体。静态库的文件内容，通常包含一堆程序员自定的变量与函数，其内容不像动态链接库那么复杂，在编译期间由编译器与链接器将它集成至应用程序内，并制作成目标文件以及可以独立运作的可执行文件。而这个可执行文件与编译可执行文件的程序，都是一种程序的静态创建（static build）。

![img](https://note.youdao.com/yws/public/resource/1cdba699ec7b6efece55aae67366a809/xmlnote/wcp1578840227309631/F5B0697830084F82BB5361D596692C1C/13309)

**动态库**

- 静态库很方便，但是如果我们只是想用库中的某一个函数，却仍然得把所有的内容都链接进去。一个更现代的方法则是使用共享库，避免了在文件中静态库的大量重复。
- 动态链接可以在首次载入的时候执行(load-time linking)，这是 Linux 的标准做法，会由动态链接器ld-linux.so 完成，比方标准 C 库(libc.so) 通常就是动态链接的，这样**所有的程序可以共享同一个库，而不用分别进行封装。**
- 动态链接也可以在程序开始执行的时候完成(run-time linking)，在 Linux 中使用 dlopen()接口来完成（会使用函数指针），通常用于分布式软件，高性能服务器上。而且共享库也可以在多个进程间共享。
- **链接使得我们可以用多个对象文件构造我们的程序。可以在程序的不同阶段进行（编译、载入、运行期间均可），理解链接可以帮助我们避免遇到奇怪的错误**。

![img](https://note.youdao.com/yws/public/resource/1cdba699ec7b6efece55aae67366a809/xmlnote/wcp1578840227309631/387EEB37FB7545729061E1402882F109/13311)

区别：

1. 使用静态库的时候，静态链接库要参与编译，在生成执行文件之前的链接过程中，要将静态链接库的全部指令直接链接入可执行文件中。而动态库提供了一种方法，使进程可以调用不属于其可执行代码的函数。函数的可执行代码位于一个.dll文件中，该dll包含一个或多个已被编译，链接并与使用它们的进程分开储存的函数。
2. 静态库中不能再包含其他动态库或静态库，而在动态库中还可以再包含其他动态或者静态库。
3. 静态库在编译的时候，就将库函数装在到程序中去了，而动态库函数必须在运行的时候才被装载，所以使用静态库速度快一些。

**12.虚拟内存？优缺点？**

定义：具有请求调入功能和置换功能，能从逻辑上对内存容量加以扩充得一种存储器系统。其逻辑容量由内存之和和外存之和决定。

与传统存储器比较虚拟存储器有以下三个主要特征：

- 多次性，是指无需在作业运行时一次性地全部装入内存，而是允许被分成多次调入内存运行。
- 对换性，是指无需在作业运行时一直常驻内存，而是允许在作业的运行过程中，进行换进和换出。
- 虚拟性，是指从逻辑上扩充内存的容量，使用户所看到的内存容量，远大于实际的内存容量。

虚拟内存的实现有以下两种方式：

- 请求**分页**存储管理。
- 请求**分段**存储管理。

**13.页面置换算法（****很重要****）**

操作系统将内存按照页面进行管理，在需要的时候才把进程相应的部分调入内存。当产生缺页中断时，需要选择一个页面写入。如果要换出的页面在内存中被修改过，变成了“脏”页面，那就需要先写会到磁盘。页面置换算法，就是要选出最合适的一个页面，使得置换的效率最高。页面置换算法有很多，简单介绍几个，重点介绍比较重要的LRU及其实现算法。

**一、最优页面置换算法**

最理想的状态下，我们给页面做个标记，挑选一个最远才会被再次用到的页面调出。当然，这样的算法不可能实现，因为不确定一个页面在何时会被用到。

**二、先进先出页面置换算法（FIFO）及其改进**

这种算法的思想和队列是一样的，该算法总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面予淘汰。实现：把一个进程已调入内存的页面按先后次序链接成一个队列，并且设置一个指针总是指向最老的页面。缺点：对于有些经常被访问的页面如含有全局变量、常用函数、例程等的页面，不能保证这些不被淘汰。

**三、最近最少使用页面置换算法LRU（Least Recently Used）**

根据页面调入内存后的使用情况做出决策。LRU置换算法是选择最近最久未使用的页面进行淘汰。

1.为每个在内存中的页面配置一个移位寄存器。（P165）定时信号将每隔一段时间将寄存器右移一位。最小数值的寄存器对应页面就是最久未使用页面。

2.利用一个特殊的栈保存当前使用的各个页面的页面号。每当进程访问某页面时，便将该页面的页面号从栈中移出，将它压入栈顶。因此，栈顶永远是最新被访问的页面号，栈底是最近最久未被访问的页面号。

[链接：分页内存管理（把虚拟内存空间和物理内存空间均划分为大小相同的页面等内容）](https://www.cnblogs.com/edisonchou/p/5094066.html)

[链接：分段内存管理](http://www.cnblogs.com/edisonchou/p/5115242.html)

**14.中断与系统调用**

**所谓的中断就是在计算机执行程序的过程中，由于出现了某些特殊事情，使得CPU暂停对程序的执行，转而去执行处理这一事件的程序。等这些特殊事情处理完之后再回去执行之前的程序。**中断一般分为三类：

- 由计算机硬件异常或故障引起的中断，称为**内部异常中断**；
- 由程序中执行了引起中断的指令而造成的中断，称为**软中断**（这也是和我们将要说明的系统调用相关的中断）；
- 由外部设备请求引起的中断，称为**外部中断**。简单来说，对中断的理解就是对一些特殊事情的处理。

与中断紧密相连的一个概念就是**中断处理程序**了。当中断发生的时候，系统需要去对中断进行处理，对这些中断的处理是由操作系统内核中的特定函数进行的，这些处理中断的特定的函数就是我们所说的中断处理程序了。

另一个与中断紧密相连的概念就是**中断的优先级**。中断的优先级说明的是当一个中断正在被处理的时候，处理器能接受的中断的级别。中断的优先级也表明了中断需要被处理的紧急程度。**每个中断都有一个对应的优先级，当处理器在处理某一中断的时候，只有比这个中断优先级高的中断可以被处理器接受并且被处理。**优先级比这个当前正在被处理的中断优先级要低的中断将会被忽略。

**典型的中断优先级如下所示：**

- **机器错误 > 时钟 > 磁盘 > 网络设备 > 终端 > 软件中断**

在讲系统调用之前，先说下**进程的执行在系统上的两个级别**：用户级和核心级，也称为**用户态和系统态(user mode and kernel mode)**。

**用户空间就是用户进程所在的内存区域**，相对的，**系统空间就是操作系统占据的内存区域**。用户进程和系统进程的所有数据都在内存中。**处于用户态的程序只能访问用户空间，而处于内核态的程序可以访问用户空间和内核空间****。**

**用户态切换到内核态的方式如下：**

- **系统调用**：程序的执行一般是在用户态下执行的，但当程序需要使用操作系统提供的服务时，比如说打开某一设备、创建文件、读写文件（这些均属于系统调用）等，就需要向操作系统发出调用服务的请求，这就是系统调用。
- **异常**：当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。
- **外围设备的中断：**当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。

**用户态和核心态(内核态）之间的区别是什么呢？**

​       **权限不一样。**

- **用户态的进程能存取它们自己的指令和数据，但不能存取内核指令和数据（或其他进程的指令和数据）**。
- **核心态下的进程能够存取内核和用户地址某些机器指令是特权指令，在用户态下执行特权指令会引起错误。**在系统中内核并不是作为一个与用户进程平行的估计的进程的集合。

**15.C++多线程，互斥，同步**

**同步和互斥**

当有多个线程的时候，经常需要去**同步(注：同步不是同时刻)**这些线程以访问同一个数据或资源。例如，假设有一个程序，其中一个线程用于把文件读到内存，而另一个线程用于统计文件中的字符数。当然，在把整个文件调入内存之前，统计它的计数是没有意义的。但是，由于每个操作都有自己的线程，操作系统会把两个线程当作是互不相干的任务分别执行，这样就可能在没有把整个文件装入内存时统计字数。为解决此问题，你必须使两个线程**同步**工作。

所谓**同步**，是指在不同进程之间的若干程序片断，它们的运行必须严格按照规定的某种先后次序来运行，这种先后次序依赖于要完成的特定的任务。如果用对资源的访问来定义的话，同步是指在互斥的基础上（大多数情况），通过其它机制实现访问者对资源的有序访问。在大多数情况下，同步已经实现了互斥，特别是所有写入资源的情况必定是互斥的。少数情况是指可以允许多个访问者同时访问资源。

所谓**互斥**，是指散布在不同进程之间的若干程序片断，当某个进程运行其中一个程序片段时，其它进程就不能运行它们之中的任一程序片段，只能等到该进程运行完这个程序片段后才可以运行。如果用对资源的访问来定义的话，互斥某一资源同时只允许一个访问者对其进行访问，具有唯一性和排它性。但互斥无法限制访问者对资源的访问顺序，即访问是无序的。

**多线程同步和互斥有几种实现方法**

线程间的同步方法大体可分为两类：用户模式和内核模式。顾名思义，内核模式就是指利用系统内核对象的单一性来进行同步，使用时需要切换内核态与用户态，而用户模式就是不需要切换到内核态，只在用户态完成操作。

用户模式下的方法有：原子操作（例如一个单一的全局变量），临界区。

内核模式下的方法有：事件，信号量，互斥量。

1、**临界区：**通过对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问。 

2、**互斥量：**为协调共同对一个共享资源的单独访问而设计的。 

3、**信号量：**为控制一个具有有限数量用户资源而设计。 

4、**事 件：**用来通知线程有一些事件已发生，从而启动后继任务的开始。

**16.逻辑地址 Vs 物理地址 Vs 虚拟内存**

- **所谓的逻辑地址，是指计算机用户(例如程序开发者)，看到的地址。**例如，当创建一个长度为100的整型数组时，操作系统返回一个逻辑上的连续空间：指针指向数组第一个元素的内存地址。由于整型元素的大小为4个字节，故第二个元素的地址时起始地址加4，以此类推。事实上，**逻辑地址并不一定是元素存储的真实地址，即数组元素的物理地址(在内存条中所处的位置)，并非是连续的，只是操作系统通过地址映射，将逻辑地址映射成连续的，这样更符合人们的直观思维**。
- 另一个重要概念是虚拟内存。操作系统读写内存的速度可以比读写磁盘的速度快几个量级。但是，内存价格也相对较高，不能大规模扩展。于是，**操作系统可以通过将部分不太常用的数据移出内存，“存放到价格相对较低的磁盘缓存，以实现内存扩展**。操作系统还可以通过算法预测哪部分存储到磁盘缓存的数据需要进行读写，提前把这部分数据读回内存。**虚拟内存空间相对磁盘而言要小很多，因此，即使搜索虚拟内存空间也比直接搜索磁盘要快。唯一慢于磁盘的可能是，内存、虚拟内存中都没有所需要的数据，最终还需要从硬盘中直接读取。**这就是为什么内存和虚拟内存中需要存储会被重复读写的数据，否则就失去了缓存的意义。现代计算机中有一个专门的**转译缓冲区(Translation Lookaside Buffer，TLB)**，用来实现虚拟地址到物理地址的快速转换。

**与内存／虚拟内存相关的还有如下两个概念：**

**1) Resident Set**

- 当一个进程在运行的时候，操作系统不会一次性加载进程的所有数据到内存，只会加载一部分正在用，以及预期要用的数据。其他数据可能存储在虚拟内存，交换区和硬盘文件系统上。**被加载到内存的部分就是resident set。**

**2) Thrashing**

- 由于resident set包含预期要用的数据，理想情况下，进程运行过程中用到的数据都会逐步加载进resident set。但事实往往并非如此：**每当需要的内存页面(page)不在resident set中时，操作系统必须从虚拟内存或硬盘中读数据，这个过程被称为内存页面错误(page faults)。当操作系统需要花费大量时间去处理页面错误的情况就是thrashing。**

**参考链接：https://blog.csdn.net/newcong0123/article/details/52792070**

**17.内部碎片与外部碎片**

在内存管理中，**内部碎片**是已经被分配出去的的内存空间大于请求所需的内存空间。

**外部碎片**是指还没有分配出去，但是由于大小太小而无法分配给申请空间的新进程的内存空间空闲块。

固定分区存在内部碎片，可变式分区分配会存在外部碎片；

**页式虚拟存储**系统存在**内部碎片**；**段式虚拟存储**系统存在**外部碎片**

为了有效的利用内存，使内存产生更少的碎片，要对内存分页，内存以页为单位来使用，最后一页往往装不满，于是形成了内部碎片。

为了共享要分段，在段的换入换出时形成外部碎片，比如5K的段换出后，有一个4k的段进来放到原来5k的地方，于是形成1k的外部碎片。

**18.同步和互斥的区别**

​        当有多个线程的时候，经常需要去同步这些线程以访问同一个数据或资源。例如，假设有一个程序，其中一个线程用于把文件读到内存，而另一个线程用于统计文件中的字符数。当然，在把整个文件调入内存之前，统计它的计数是没有意义的。但是，由于每个操作都有自己的线程，操作系统会把两个线程当作是互不相干的任务分别执行，这样就可能在没有把整个文件装入内存时统计字数。为解决此问题，你必须使两个线程同步工作。

​      所谓**同步**，是指散步在不同进程之间的若干程序片断，它们的运行必须严格按照规定的某种先后次序来运行，这种先后次序依赖于要完成的特定的任务。如果**用对资源的访问来定义的话，同步是指在互斥的基础上（大多数情况），通过其它机制实现访问者对资源的有序访问。在大多数情况下，同步已经实现了互斥，特别是所有写入资源的情况必定是互斥的。少数情况是指可以允许多个访问者同时访问资源。**

​      所谓**互斥**，是指散布在不同进程之间的若干程序片断，当某个进程运行其中一个程序片段时，其它进程就不能运行它们之中的任一程序片段，只能等到该进程运行完这个程序片段后才可以运行。如果**用对资源的访问来定义的话，互斥某一资源同时只允许一个访问者对其进行访问，具有唯一性和排它性。但互斥无法限制访问者对资源的访问顺序，****即访问是无序的****。**

**20.同步与异步**

**同步：**

- 同步的定义：是指一个进程在执行某个请求的时候，若该请求需要一段时间才能返回信息，那么，这个进程将会一直等待下去，直到收到返回信息才继续执行下去。
- 特点：

1. 同步是阻塞模式；
2. 同步是按顺序执行，执行完一个再执行下一个，需要等待，协调运行；

**异步：**

- 是指进程不需要一直等下去，而是继续执行下面的操作，不管其他进程的状态。当有消息返回时系统会通知进程进行处理，这样可以提高执行的效率。
- 特点：

1. 异步是非阻塞模式，无需等待；
2. 异步是彼此独立，在等待某事件的过程中，继续做自己的事，不需要等待这一事件完成后再工作。线程是异步实现的一个方式。

**同步与异步的优缺点：**

- 同步可以避免出现死锁，读脏数据的发生。一般共享某一资源的时候，如果每个人都有修改权限，同时修改一个文件，有可能使一个读取另一个人已经删除了内容，就会出错，同步就不会出错。但，同步需要等待资源访问结束，浪费时间，效率低。
- 异步可以提高效率，但，安全性较低。

### 21.系统调用与库函数的区别

- **系统调用(System call)是程序向系统内核请求服务的方式。**可以包括硬件相关的服务(例如，访问硬盘等)，或者创建新进程，调度其他进程等。系统调用是程序和操作系统之间的重要接口。
- **库函数：把一些常用的函数编写完放到一个文件里，编写应用程序时调用，****这是由第三方提供的，发生在用户地址空间**。
- 在**移植性方面**，不同操作系统的系统调用一般是不同的，移植性差；而在所有的ANSI C编译器版本中，C库函数是相同的。
- 在**调用开销方面**，系统调用需要在用户空间和内核环境间切换，开销较大；而库函数调用属于“过程调用”，开销较小。

### 22.守护、僵尸、孤儿进程的概念

- **守护进程**：运行在后台的一种特殊进程，**独立于控制终端并周期性地执行某些任务**。
- **僵尸进程**：一个进程 fork 子进程，子进程退出留下了一个僵尸结构，而父进程没有wait/waitpid子进程，那么**子进程的进程描述符仍保存在系统中**，这样的进程称为僵尸进程。
- **孤儿进程**：一个**父进程退出，而它的一个或多个子进程还在运行**，这些子进程称为孤儿进程。（孤儿进程将由 init 进程收养并对它们完成状态收集工作）

#### 如何处理僵尸进程？

- 父进程使用`wait()`或者`waitpid()`之类的函数等待子进程退出

```c
int main(int argc, char *argv[]){
	pid_t pid;
  pid = fork();
	if(pid<1){
    perroe("fail to fork");
		exit(1);
  }
	else if(pid==0){
    sleep(5);
		exit(0);
  }	
	else{
    sleep(30);  // 睡眠30S，等待子进程完成任务
    wait(NULL); // 处理子进程
    sleep(30);
  }
	return EXIT_SUCCESS;
}
```

父进程创建子进程后30s调用wait()函数，等待子进程退出，回收子进程的资源，这也意味着子进程将会成为僵尸进程30s-5s=25s。 

- 用两次fork()，而且使紧跟的子进程直接退出，使得孙子进程成为孤儿进程，从而init进程将负责清除这个孤儿进程。

​    上述方法比较简洁，但是有个问题就是子进程如果处理的时间比较长的话，主进程会被挂起。比如： 

```c
socket()
bind()
listen()
while(1){
    accept()
    if(fork()==0){   //进入子进程处理
        while(1){
            read()
            process()
            write()
        }
        close()
        exit()
    }
    wait()   //如果这里父进程进行wait()操作，则很有可能在此处挂起，而如果不进行wait()操作，则此处又产生了僵尸进程。
}
```

对于这样的情况可以采取连续fork()两次的方法。简而言之，首先父进程首先创建子进程，子进程创建孙子进程，**由孙子进程处理事务，而子进程再创建完孙子进程后就退出**。此时，孙子进程的父进程，也就是子进程退出了，**因此孙子进程变为了一个孤儿进程**，Linux进程处理孤儿的进程的方式，**是init进程接管孤儿进程，而init进程的子进程不会成为僵尸进程**。 所以上述的伪代码可以写为：

```c
pid_t pid;
pid = fork();
if(pid<1){
    perroe("fail to fork");
    exit(1);
}
else if(pid==0){
    if(fork()==0){
        /*孙子进程在这里处理事务*/
       process();
       close()
       exit()
    }
    else{
        /*子进程在这里退出，使得孙子进程成为init进程的儿子，从而避免僵尸进程的产生*/
        close()
        exit()          //<子进程在此退出
    }
}
else{
    /* 等待子进程的退出 */
    if(waitpid(pid, NULL, 0) != pid){
        printf("waitpid error.\n");
        exit(1);
    }
    //<爷爷进程进入下一轮的处理。
}
```

​    **3）还有一种处理方法是使用信号处理函数来处理（**[**参考**](https://blog.csdn.net/sty23122555/article/details/51199781)**）：**

```c
int num_clients = 0;   
int dead_clients = 0;   
voidsig_chld_handler(int sig){   
pid_t pid;   
if (sig == SIGCHLD) {   
        pid = wait(NULL);   
    printf("A child dead, current child number: %d, id: %d/n", ++dead_clients, pid);   
    }   
}   
int main(int argc, char **argv){   
    pid_t pid;   
    signal(SIGCHLD, sig_chld_handler);   
    for (int i = 0; i < 30; i++) {   
        if ((pid = fork()) == 0) {   
            exit(0);   
        } else if (pid > 0) {   
            printf("A child created, current child number: %d, id: %d/n", ++num_clients, pid);   
        }   
    }   
    sleep(10);   
    return 0;   
} 
```

父进程首先注册一个信号处理函数`signal(SIGCHLD, sig_chld_handler)`，**然后每当子进程退出的时候父进程都会受到SIGCHLD信号，触发`sig_chld_handler()`函数，调用`wait()`函数等待子进程的退出**。

### 23.Semaphore(信号量) Vs Mutex(互斥锁)

- 当用户创立多个线程／进程时，如果不同线程／进程同时读写相同的内容，则可能造成读写错误，或者数据不一致。此时，需要通过加锁的方式，控制临界区(critical section)的访问权限。对于semaphore而言，在初始化变量的时候可以控制允许多少个线程／进程同时访问一个临界区，其他的线程／进程会被堵塞，直到有人解锁。
- Mutex相当于只允许一个线程／进程访问的semaphore。此外，根据实际需要，人们还实现了一种读写锁(read-write lock)，它允许同时存在多个阅读者(reader)，但任何时候至多只有一个写者(writer)，且不能于读者共存。

### 26.线程共享资源和独占资源问题

[参考链接](https://www.cnblogs.com/baoendemao/p/3804677.html)

一个进程中的所有线程共享该进程的地址空间，但它们有各自独立的（/私有的）栈(stack)，Windows线程的缺省堆栈大小为1M。堆(heap)的分配与栈有所不同，一般是一个进程有一个C运行时堆，这个堆为本进程中所有线程共享，windows进程还有所谓进程默认堆，用户也可以创建自己的堆。 

线程切换的时候实际上切换的是一个可以称之为线程控制块的结构（TCB）,里面保存所有将来用于恢复线程环境必须的信息，包括所有必须保存的寄存器集，线程的状态等。

- **堆：**是大家共有的空间，分全局堆和局部堆。全局堆就是所有没有分配的空间，局部堆就是用户分配的空间。堆在操作系统对进程初始化的时候分配，运行过程中也可以向系统要额外的堆，但是记得用完了要还给操作系统，要不然就是内存泄漏。

- **栈：**是个线程独有的，保存其运行状态和局部自动变量的。栈在线程开始的时候初始化，每个线程的栈互相独立，因此，栈是　thread safe的。操作系统在切换线程的时候会自动的切换栈，就是切换SS / ESP寄存器。栈空间不需要在高级语言里面显式的分配和释放。

![img](https://note.youdao.com/yws/public/resource/1cdba699ec7b6efece55aae67366a809/xmlnote/wcp1578840227309631/ACCD87BE65BA4A5D83E0BA442D1801B3/13310)